{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ3QJk4i3wB9"
      },
      "source": [
        "# installs and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiDV5Bfi34HM"
      },
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install turicreate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dF2fG3f6w9z"
      },
      "source": [
        "# imports\n",
        "import os.path\n",
        "import glob \n",
        "import fitz\n",
        "import turicreate as tc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULBhYf1_39D4"
      },
      "source": [
        "# files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL4kuc6V4A8w"
      },
      "source": [
        "files = [('/content/drive/MyDrive/big_data/project/Africa_2019.PDF',12, 'ANGOLA'),\n",
        "         ('/content/drive/MyDrive/big_data/project/America_2019.PDF',16,'ARGENTINA'),\n",
        "         ('/content/drive/MyDrive/big_data/project/Asia_2019.PDF',6,'AFGHANISTAN'),\n",
        "         ('/content/drive/MyDrive/big_data/project/Europe1_2019.PDF',5,'ARMENIA'),\n",
        "         ('/content/drive/MyDrive/big_data/project/Europe2_2019.PDF',7,'ALBANIA'),\n",
        "         ('/content/drive/MyDrive/big_data/project/MiddleEast_2019.PDF',11,'ALGERIA')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL4N0K9z4Heo"
      },
      "source": [
        "# Extract data from pdf by table of content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztkcRSrB4By4"
      },
      "source": [
        "# extract toc from pdf \n",
        "def extract_toc_data(filename):\n",
        "  pdf_data = []\n",
        "  with fitz.open(filename) as doc:\n",
        "    toc = get_toc_by_filename(filename)\n",
        "    if len(toc) == 0:\n",
        "      toc = doc.getToC()\n",
        "      toc = [t for t in toc if t[0] == 1]\n",
        "      toc = [t[1].strip() for t in toc if len(t[1])>1]\n",
        "    toc = create_toc(toc)\n",
        "    for page in doc:\n",
        "      pdf_data.append(page.getText())\n",
        "  return toc,pdf_data \n",
        "\n",
        "# crete toc and clean contents\n",
        "def create_toc(toc):\n",
        "  top_toc = []\n",
        "  for c in toc :\n",
        "    c = c.split('/')[0]\n",
        "    c = c.replace(u'\\xa0', u' ')\n",
        "    top_toc.append(c.upper())\n",
        "  return top_toc\n",
        "\n",
        "# get toc if not exsist in file\n",
        "def get_toc_by_filename(filename):\n",
        "  path_split = filename.split('/')\n",
        "  name = path_split[len(path_split) -1 ].split('.')[0]+'.txt'\n",
        "  path_split[len(path_split) -1 ] = name\n",
        "  filename ='/'.join(path_split)\n",
        "  if os.path.isfile(filename):\n",
        "    file = open(filename, \"r\")\n",
        "    toc = file.read()\n",
        "    toc = toc.split(',')\n",
        "    return toc\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "# get all pdf text\n",
        "def get_all_text(pages):\n",
        "  text = \"\"\n",
        "  for page in pages :\n",
        "    text += page\n",
        "  text = \" \".join(text.split())\n",
        "  text = text.replace('\\n',\" \")\n",
        "  return text\n",
        "# get only relevent toc\n",
        "def get_relevent_toc(toc,first_toc):\n",
        "  new_toc =[]\n",
        "  for t in toc :\n",
        "    if not (t[-1] >='A' and t[-1] <='Z'):\n",
        "      t = t[:-1]\n",
        "    new_toc.append(t.strip())\n",
        "  index = new_toc.index(first_toc)\n",
        "  return new_toc[index:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u0HsDEf4jWv"
      },
      "source": [
        "def parse_pdf_by_toc(filename,start_page,first_toc='Afghanistan'):\n",
        "  parse_text = dict()\n",
        "  toc, pages = extract_toc_data(filename)\n",
        "  text = get_all_text(pages[start_page:])\n",
        "  toc = get_relevent_toc(toc,first_toc)\n",
        "  for i in range(len(toc)-1):\n",
        "    start = toc[i].upper()\n",
        "    end = toc[i+1].upper()\n",
        "    start_index = text.find(start)\n",
        "    end_index = text.find(end)\n",
        "    toc_text = text[start_index:end_index]\n",
        "    parse_text[start] = toc_text\n",
        "    if start_index == -1 or end_index == -1 :\n",
        "      print(\"Not found: \" + start + \" end_index: \"+str(end_index) + \" start_index: \"+ str(start_index) )\n",
        "    text = text[end_index: len(text)]\n",
        "  last_toc = toc[-1].upper()\n",
        "  parse_text[last_toc] = text\n",
        "  return parse_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hyVckNZ4yNy"
      },
      "source": [
        "# save files in drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAMFtx3v4myC"
      },
      "source": [
        "# save each country file in drive \n",
        "\n",
        "for file in files:\n",
        "  text_dict = parse_pdf_by_toc(file[0],file[1],file[2])\n",
        "  print(text_dict.keys())\n",
        "  print(gal)\n",
        "  pdf_path = file[0] \n",
        "  pdf_year = pdf_path.split('_')[2].split('.')[0]\n",
        "  path = '/content/drive/MyDrive/big_data/project/Data/'\n",
        "  for key, value in text_dict.items():\n",
        "    if(len(key)) < 4:\n",
        "      continue\n",
        "    file_path = path + pdf_year+ '/'  + key +'.txt'\n",
        "    f = open(file_path, \"w\")\n",
        "    f.write(value)\n",
        "    f.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0gPjzkq42ki"
      },
      "source": [
        "# combine all countries data to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znaDgazQ48Yx"
      },
      "source": [
        "path = '/content/drive/MyDrive/big_data/project/Data//'\n",
        "files = [f for f in glob.glob(path + \"**/*.txt\", recursive=True)]\n",
        "years = []\n",
        "country_names = []\n",
        "texts = []\n",
        "for file_path in files :\n",
        "  file = open(file_path,'r')\n",
        "  text = file.read()\n",
        "  split_path = file_path.split('/')\n",
        "  year = split_path[-2]\n",
        "  country_name = split_path[-1][:-4]\n",
        "  country_name = country_name.lower()\n",
        "  years.append(year)\n",
        "  country_names.append(country_name.strip())\n",
        "  texts.append(text)\n",
        "\n",
        "sframe = tc.SFrame({'year':years,'country':country_names, 'text':texts})\n",
        "countries = sframe.groupby('country',{'count':tc.aggregate.COUNT_DISTINCT('year')})\n",
        "countries = countries[countries['count'] == 3]\n",
        "sframe = sframe.filter_by(countries['country'].unique(),'country')\n",
        "sframe"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}